{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers"
      ],
      "metadata": {
        "id": "I6YsZgLDoYjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install flask_cors\n",
        "!pip install requests\n",
        "!pip install Flask"
      ],
      "metadata": {
        "id": "B-xZ8msjTjuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model_for_I2T = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "\n",
        "def generate_caption(raw_image):\n",
        "  text = \"a photography of\"\n",
        "  inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
        "\n",
        "  out = model_for_I2T.generate(**inputs, min_length=20, max_length=50)\n",
        "  caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "  return caption\n",
        "\n",
        "def generate_caption_by_file(file):\n",
        "  raw_image_bytes = file.read()\n",
        "  raw_image = Image.open(io.BytesIO(raw_image_bytes))\n",
        "\n",
        "  caption = generate_caption(raw_image)\n",
        "  return caption\n",
        "\n",
        "def generate_caption_by_url(image_url):\n",
        "  raw_image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "  caption = generate_caption(raw_image)\n",
        "  return caption\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZU6RKDYBJp6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "modelid = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelid,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelid)"
      ],
      "metadata": {
        "id": "SQmBRFpkKIxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getClassfication(prompt):\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\":\n",
        "      \"\"\"\n",
        "      You are an AI assistant that performs food classification and calorie estimation. From the food descriptions provided by the user, accurately extract the following two pieces of information.\n",
        "        1. Category : Identify the major food or beverage categories mentioned in the description. Use food categories [\"Alcohol/Beverage\", \"Noodle dish\", \"Vegetable\", \"Meat\", \"Grain\", \"Dessert/Snack\", other]. If there is more than one food category, identify the most primary one.\n",
        "        2. Calory: Estimate the general calorie content of the applicable food. If exact information is not available, please provide a reasonable approximation and output numbers only.\n",
        "        3. Energy type: Identify the category by energy type for that meal from Category and Calory. Use the energy category (DYNAMISM , VITALITY  , SERENITY ).\n",
        "        4. Food name: Get the food name from the input text.\n",
        "        5. Impressions: You have eaten this meal. Give us your impressions of this simple meal..\n",
        "        Always provide output in the Json format:\n",
        "        \"{\n",
        "          \"Category\": [Category] ,\n",
        "          \"Calory\": [Calories],\n",
        "          \"Energy type\": [Energy type],\n",
        "          \"Food name\":[Food name],\n",
        "          \"Impressions\": [Impressions]\n",
        "          }\"\n",
        "        \"\"\"\n",
        "      },\n",
        "      {\"role\": \"assistant\", \"content\":\n",
        "      \"\"\" Use Json format to output the result.\n",
        "      Output example:\n",
        "        {\n",
        "          \"Category\": \"Alcohol/Beverage\" ,\n",
        "          \"Calory\": \"100\",\n",
        "          \"Energy type\": \"DYNAMISM\",\n",
        "          \"Food name\": \"Ramen\",\n",
        "          \"Impressions\": \"It was very good ramen! It's my favorite!\"\n",
        "        }\n",
        "      \"\"\"\n",
        "      },\n",
        "      {\"role\": \"user\", \"content\": prompt},\n",
        "  ]\n",
        "\n",
        "  pipe = pipeline(\n",
        "      \"text-generation\",\n",
        "      model=model,\n",
        "      tokenizer=tokenizer,\n",
        "  )\n",
        "\n",
        "  generation_args = {\n",
        "      \"max_new_tokens\": 500,\n",
        "      \"return_full_text\": False,\n",
        "      \"temperature\": 0.0,\n",
        "      \"do_sample\": False,\n",
        "      \"use_cache\": False,\n",
        "  }\n",
        "\n",
        "  output = pipe(messages, **generation_args)\n",
        "  return output[0]['generated_text']"
      ],
      "metadata": {
        "id": "3dHl6WCDTw5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run API\n",
        "from flask import Flask, send_file, render_template, request, make_response,jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok, conf\n",
        "import json\n",
        "import os\n",
        "import werkzeug\n",
        "from datetime import datetime\n",
        "\n",
        "# ngrokトークンを設定\n",
        "conf.get_default().auth_token = \"YOUR_AUTH_TOKEN\"\n",
        "NGROK_DOMAIN = \"YOUR_NGROK_DOMAIN\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# limit upload file size : 3MB\n",
        "app.config['MAX_CONTENT_LENGTH'] = 3 * 1024 * 1024\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return \"I'm ready!\"\n",
        "\n",
        "@app.route('/img2txt', methods=['POST'])\n",
        "def img2text():\n",
        "\n",
        "    file = request.files.get('file')\n",
        "    if 'file' not in request.files:\n",
        "        make_response(jsonify({'result':'file is required.'}))\n",
        "\n",
        "    file = request.files['file']\n",
        "    fileName = file.filename\n",
        "    if '' == fileName:\n",
        "        make_response(jsonify({'result':'filename must not empty.'}))\n",
        "\n",
        "    prompt = generate_caption_by_file(file)\n",
        "    print(\"----------------------\")\n",
        "    print(prompt)\n",
        "\n",
        "    output = getClassfication(prompt)\n",
        "    print(\"========== ===========\")\n",
        "    print(output)\n",
        "\n",
        "    return make_response(jsonify({'result':output}))\n",
        "\n",
        "@app.errorhandler(werkzeug.exceptions.RequestEntityTooLarge)\n",
        "def handle_over_max_file_size(error):\n",
        "    print(\"werkzeug.exceptions.RequestEntityTooLarge\")\n",
        "    return 'result : file size is overed.'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  public_url = ngrok.connect(5000, hostname=NGROK_DOMAIN)\n",
        "  print(f\"ngrok URL: {public_url}\")\n",
        "  app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "42LPEsDVTp3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}